{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4bc23af-f205-4a21-98a5-411fd2a0ecda",
   "metadata": {},
   "source": [
    "## Create Source Attribution Modeling Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09baf74d-78b8-41b4-8b86-36fa8ddd655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import imputation_utils\n",
    "import general_utils\n",
    "import geopandas as gpd\n",
    "import rpy2.robjects as robjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1955a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source data output location\n",
    "source_attribution_modeling_dataset_output_folder = '../../data/modeling_data/source_attribution'\n",
    "\n",
    "# Lookup table to impute missing RL/MDL values\n",
    "rl_mdl_file = ('../../data/Extracted lab report data/RL_MDL_lookup_table.csv')\n",
    "\n",
    "# file location of waste/sludge effluent data\n",
    "residential_file = '../../data/residential/Wastewater Treatment Systems Effluent  -  Sludge 2021-08.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8956fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "run constants.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d145459c-dcaa-4c52-ac1a-08bf5d7dfa35",
   "metadata": {},
   "source": [
    "### Source Attribution Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4c69849-3170-4421-855f-3883fd7a9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "disposal_sites_info = pd.read_parquet(f'{disposal_sites_output}.csv')\n",
    "\n",
    "# Lookup table to impute missing RL/MDL values\n",
    "rl_mdl_lookup = pd.read_csv(rl_mdl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec3466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pfas_vars = pd.read_csv(pfas_dict['file_location'])\n",
    "\n",
    "# Get list of pfas compounds\n",
    "pfas_vars = df_pfas_vars[df_pfas_vars[pfas_dict['pfas_filter_col']] == 1][pfas_dict['acronym_col']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58119757",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac9319-cfdd-4e82-8235-cb87e7c89e98",
   "metadata": {},
   "source": [
    "##### Residential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "382f42f3-45f5-491a-9624-4a6afe3c9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['../../data/residential/ros/input', '../../data/residential/ros/output', '../../data/residential/ros/analysis' ,'../../data/residential/imputed'] \n",
    "\n",
    "for path in paths:\n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(path)\n",
    "\n",
    "    if not isExist:\n",
    "      # Create a new directory because it does not exist \n",
    "      os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59e8670b-f2bb-4bba-ab73-569a6f705f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_residential_df = pd.read_csv(residential_file, encoding='iso-8859-1')\n",
    "\n",
    "residential_df = orig_residential_df.copy()\n",
    "residential_df.rename(columns = {'PFBS    ' : 'PFBS'}, inplace = True)\n",
    "\n",
    "unique_vars = ['Facility', 'Sample Collection Date', 'Sample Field ID', 'Sample Laboratory ID #', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "acaa26e8-fbda-4410-9432-b503d771f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrl_dict, mdl_dict, pfas_vars = imputation_utils.create_mrl_mdl_dict(residential_df, pfas_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78caf9cb-2b77-437a-98a8-157c52ba92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfas_avail = list(set(pfas18).intersection(residential_df.columns))\n",
    "residential_df = residential_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8da9b88f-9e2f-49e2-bae0-7087ab8201fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEtFOSAA :\n",
      "93.87 % ND - Not included in analysis\n",
      "count    212.000000\n",
      "mean       0.614170\n",
      "std        0.646551\n",
      "min        0.124000\n",
      "25%        0.491000\n",
      "50%        0.491000\n",
      "75%        0.491000\n",
      "max        5.980000\n",
      "Name: Result_val, dtype: float64\n",
      "PFTA :\n",
      "99.06 % ND - Not included in analysis\n",
      "count    212.000000\n",
      "mean       0.507175\n",
      "std        0.188821\n",
      "min        0.075000\n",
      "25%        0.491000\n",
      "50%        0.491000\n",
      "75%        0.491000\n",
      "max        2.300000\n",
      "Name: Result_val, dtype: float64\n",
      "NMeFOSAA :\n",
      "95.75 % ND - Not included in analysis\n",
      "count    212.000000\n",
      "mean       0.668896\n",
      "std        1.520671\n",
      "min        0.044000\n",
      "25%        0.440000\n",
      "50%        0.440000\n",
      "75%        0.440000\n",
      "max       15.400000\n",
      "Name: Result_val, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_imputation_dict = {}\n",
    "for pfas in pfas_avail:\n",
    "    residential_df[pfas] = pd.to_numeric(residential_df[pfas], errors = 'coerce')\n",
    "    \n",
    "    id_vars=['index','Facility', 'Sample Collection Date', 'Sample Field ID',]\n",
    "    pfas_df = pd.melt(residential_df, id_vars=id_vars, value_vars=[pfas]).rename(columns = {'value' : 'Result_val', 'variable' : 'Acronym'})\n",
    "    mrl_df = pd.melt(residential_df, id_vars=id_vars, value_vars=[mrl_dict[pfas]]).rename(columns = {'value' : 'RL'}).drop(columns = 'variable')\n",
    "    mdl_df = pd.melt(residential_df, id_vars=id_vars, value_vars=[mdl_dict[pfas]]).rename(columns = {'value' : 'MDL'}).drop(columns = 'variable')\n",
    "    \n",
    "    long_df = pfas_df.merge(mrl_df, on = id_vars).merge(mdl_df, on = id_vars)\n",
    "\n",
    "    long_df['Result_val'] = pd.to_numeric(long_df['Result_val'], errors = 'coerce')\n",
    "    long_df['RL'] = pd.to_numeric(long_df['RL'], errors = 'coerce')\n",
    "    long_df['MDL'] = pd.to_numeric(long_df['MDL'], errors = 'coerce')\n",
    "\n",
    "    long_df['RL'] = np.where((long_df['RL'].isna()) & (long_df['MDL'].isna()) & (long_df['Result_val'].isna()), long_df['RL'].mode()[0], long_df['RL'])\n",
    "\n",
    "    long_df['limit'] = long_df[['RL', 'MDL']].min(axis = 1)\n",
    "\n",
    "    long_df['Result_val'] = np.where(long_df['Result_val'].isna(), long_df['limit'], long_df['Result_val'])\n",
    "\n",
    "    long_df['Result_val_cen'] = np.where(long_df['Result_val'] == long_df['limit'], 1, 0)\n",
    "\n",
    "    long_df = long_df.sort_values('Result_val')\n",
    "    \n",
    "    #If % of values ND < 80% output df as csv into new folder for ROS\n",
    "    perc_non_detects = long_df['Result_val_cen'].sum() / long_df.shape[0]\n",
    "    if (long_df['Result_val_cen'].sum() / long_df.shape[0] <= 0.8):\n",
    "        long_df.to_csv(f'../../data/residential/ros/input/residential_{pfas}.csv')\n",
    "\n",
    "    # else use 1/2 limit\n",
    "    else:\n",
    "        # If less than 95% is non-detect OR detected samples do not exceed 20 ng/l \n",
    "        if ((perc_non_detects) < non_detect_threshold) | (long_df['Result_val'].describe()['max'] > 20):\n",
    "            long_df['Result_val'] = np.where(long_df['Result_val_cen'] == 1, long_df['Result_val'] / 2, long_df['Result_val'])\n",
    "            long_df.to_csv(f'../../data/residential/imputed/residential_{pfas}.csv')\n",
    "        else:\n",
    "            print(pfas, ':')\n",
    "            print(round(perc_non_detects * 100, 2), '% ND - Not included in analysis')\n",
    "            print(long_df['Result_val'].describe())\n",
    "        \n",
    "    \n",
    "    df_imputation_dict[pfas] = long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c95e497c-e613-4ae1-a8ce-f6d02797e319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: survival\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: 'NADA'\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from 'package:stats':\n",
      "\n",
      "    cor\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>ListVector with 2 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            value\n",
       "            </th>\n",
       "            <td>\n",
       "            <rpy2.rinterface_lib.sexp.NULLType object at 0x0000029F4E99BE80> [RTYPES.NILSXP]\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            visible\n",
       "            </th>\n",
       "            <td>\n",
       "            <rpy2.rinterface.BoolSexpVector object at 0x0000029F53B03600> [RTYPES.LGLSXP]\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.ListVector object at 0x0000029F53B1C100> [RTYPES.VECSXP]\n",
       "R classes: ('list',)\n",
       "[NULLType, BoolSexpVector]\n",
       "  value: <class 'rpy2.rinterface_lib.sexp.NULLType'>\n",
       "  <rpy2.rinterface_lib.sexp.NULLType object at 0x0000029F4E99BE80> [RTYPES.NILSXP]\n",
       "  visible: <class 'rpy2.rinterface.BoolSexpVector'>\n",
       "  <rpy2.rinterface.BoolSexpVector object at 0x0000029F53B03A40> [RTYPES.LGLSXP]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robjects.globalenv['ros_analysis_location'] = \"C:/Users/dcher/OneDrive/Desktop/repos/PFAS-Analysis/data/residential/ros/analysis\"\n",
    "robjects.globalenv['ros_inputs_location'] = \"C:/Users/dcher/OneDrive/Desktop/repos/PFAS-Analysis/data/residential/ros/input\"\n",
    "robjects.globalenv['ros_outputs_location'] = \"C:/Users/dcher/OneDrive/Desktop/repos/PFAS-Analysis/data/residential/ros/output\"\n",
    "\n",
    "r_source = robjects.r['source']\n",
    "r_source(\"./ros.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "358b3f03-1ba9-44c2-ae96-ee3035b29d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data back in after ROS. Overwrite with ROS modeled data\n",
    "path, dirs, files = next(os.walk(\"../../data/residential/ros/output\"))\n",
    "\n",
    "for file in files:\n",
    "    matrix_type = file.split('_')[0]\n",
    "    acronym = file.split('_')[1].split('.')[0]\n",
    "    \n",
    "    ros_df = pd.read_csv(path + '/' + file)\n",
    "    \n",
    "    data = df_imputation_dict[acronym]\n",
    "    data_filtered = data[data['Acronym'] == acronym]\n",
    "    \n",
    "    data_filtered = data_filtered.reset_index()\n",
    "\n",
    "#     # Overwrite with ROS modeled sample\n",
    "    data_filtered['Result_val'] = ros_df['modeled']\n",
    "    \n",
    "    # Error in ROS - Dropped censored values that exceed max of uncensored values. Use 1/2 imputation for these places.\n",
    "    data_filtered['Result_val'] = np.where(data_filtered['Result_val'].isna(), data_filtered['limit'] / 2, data_filtered['Result_val'])\n",
    "    \n",
    "#     # write out to imputed folder\n",
    "    data_filtered.to_csv(f'../../data/residential/imputed/{matrix_type}_{acronym}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4112be7f-7f95-4e10-96ad-bc826e2b0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all imputed data\n",
    "path, dirs, files = next(os.walk(\"../../data/residential/imputed/\"))\n",
    "\n",
    "res_imputed_data = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = pd.read_csv(f'../../data/residential/imputed/{file}')\n",
    "    res_imputed_data = pd.concat([res_imputed_data,df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c5e0687-2896-4aaf-9e25-27e7494eee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring together and convert to wide format\n",
    "res_df_wide = res_imputed_data.pivot_table(index=id_vars, columns='Acronym', values='Result_val').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8e686c0-571c-48ac-bf3a-7d1b775ffe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_wide['Units'] = 'g/kg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "832dbae6-954b-4722-b71d-01add2161326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Acronym\n",
       "index                     0\n",
       "Facility                  0\n",
       "Sample Collection Date    0\n",
       "Sample Field ID           0\n",
       "PFBS                      0\n",
       "PFDA                      0\n",
       "PFDoA                     0\n",
       "PFHpA                     0\n",
       "PFHxA                     0\n",
       "PFHxS                     0\n",
       "PFNA                      0\n",
       "PFOA                      0\n",
       "PFOS                      0\n",
       "PFTrDA                    0\n",
       "PFUnA                     0\n",
       "Units                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_wide.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4c81e90-9955-47d5-8bd2-419402907e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_wide.to_csv('../../data/modeling_data/source_attribution/residential_source.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
